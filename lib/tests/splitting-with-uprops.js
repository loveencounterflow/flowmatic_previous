// Generated by CoffeeScript 2.0.0-alpha1
(function() {
  'use strict';

  /*
  * https://github.com/devongovett/unicode-trie
  * https://github.com/devongovett/unicode-properties
  
    When implementing many Unicode algorithms such as text segmentation, normalization, bidi processing, etc.,
    fast access to character metadata is crucial to good performance. There over a million code points in the
    Unicode standard, many of which produce the same result when looked up, so an array or hash table is not
    appropriate - those data structures are fast but would require a lot of memory. The data is generally
    grouped in ranges, so you could do a binary search, but that is not fast enough for some applications.
  
    The International Components for Unicode (ICU) project came up with a data structure based on a Trie that
    provides fast access to Unicode metadata. The range data is precompiled to a serialized and flattened
    trie, which is then used at runtime to lookup the necessary data. According to my own tests, this is
    generally at least 50% faster than binary search, with not too much additional memory required.
  
  
  * https://github.com/mathiasbynens/regenerate-unicode-properties
  
  
  for reference:
  * (https://github.com/mathiasbynens/regenerate)
  * (https://github.com/mathiasbynens/unicode-8.0.0)
  * (https://github.com/mathiasbynens/node-unicode-data)
  * ncr
   */
  var $, CND, FM, LTSORT, PATH, PS, TAP, UPROPS, XXX, Xregex, badge, brown, categories, chrrpr, color, crimson, debug, description, echo, entries, f, flag, get_color, graph, group, help, i, indigo, info, j, join, k, key, len, len1, len2, lime, map, olive, orange, pink, plum, rainbow, ref1, ref2, ref3, ref4, rpr, sepia, shorten, show, steel, step, sub_categories, thin_out, toggle, ucc_of, urge, warn, whisper;

  CND = require('cnd');

  rpr = CND.rpr;

  badge = 'FLOWMATIC/TESTS/BASIC';

  debug = CND.get_logger('debug', badge);

  warn = CND.get_logger('warn', badge);

  info = CND.get_logger('info', badge);

  urge = CND.get_logger('urge', badge);

  help = CND.get_logger('help', badge);

  whisper = CND.get_logger('whisper', badge);

  echo = CND.echo.bind(CND);

  PATH = require('path');

  UPROPS = require('unicode-properties');

  TAP = require('tap');

  Xregex = require('xregexp');

  Xregex.install('astral');

  sepia = CND.sepia, plum = CND.plum, pink = CND.pink, orange = CND.orange, olive = CND.olive, indigo = CND.indigo, crimson = CND.crimson, brown = CND.brown, lime = CND.lime, steel = CND.steel;

  debug(sepia('#####', 'sepia'));

  debug(plum('#####', 'plum'));

  debug(orange('#####', 'orange'));

  debug(olive('#####', 'olive'));

  debug(indigo('#####', 'indigo'));

  debug(crimson('#####', 'crimson'));

  debug(brown('#####', 'brown'));

  debug(lime('#####', 'lime'));

  debug(steel('#####', 'steel'));

  categories = [
    {
      name: 'C',
      alias: 'Other'
    }, {
      name: 'L',
      alias: 'Letter'
    }, {
      name: 'M',
      alias: 'Mark'
    }, {
      name: 'N',
      alias: 'Number'
    }, {
      name: 'P',
      alias: 'Punctuation'
    }, {
      name: 'S',
      alias: 'Symbol'
    }, {
      name: 'Z',
      alias: 'Separator'
    }
  ];

  sub_categories = [
    {
      name: 'Cc',
      alias: 'Control'
    }, {
      name: 'Cf',
      alias: 'Format'
    }, {
      name: 'Cn',
      alias: 'Unassigned'
    }, {
      name: 'Co',
      alias: 'Private_Use'
    }, {
      name: 'Cs',
      alias: 'Surrogate'
    }, {
      name: 'Ll',
      alias: 'Lowercase_Letter'
    }, {
      name: 'Lm',
      alias: 'Modifier_Letter'
    }, {
      name: 'Lo',
      alias: 'Other_Letter'
    }, {
      name: 'Lt',
      alias: 'Titlecase_Letter'
    }, {
      name: 'Lu',
      alias: 'Uppercase_Letter'
    }, {
      name: 'Mc',
      alias: 'Spacing_Mark'
    }, {
      name: 'Me',
      alias: 'Enclosing_Mark'
    }, {
      name: 'Mn',
      alias: 'Nonspacing_Mark'
    }, {
      name: 'Nd',
      alias: 'Decimal_Number'
    }, {
      name: 'Nl',
      alias: 'Letter_Number'
    }, {
      name: 'No',
      alias: 'Other_Number'
    }, {
      name: 'Pc',
      alias: 'Connector_Punctuation'
    }, {
      name: 'Pd',
      alias: 'Dash_Punctuation'
    }, {
      name: 'Pe',
      alias: 'Close_Punctuation'
    }, {
      name: 'Pf',
      alias: 'Final_Punctuation'
    }, {
      name: 'Pi',
      alias: 'Initial_Punctuation'
    }, {
      name: 'Po',
      alias: 'Other_Punctuation'
    }, {
      name: 'Ps',
      alias: 'Open_Punctuation'
    }, {
      name: 'Sc',
      alias: 'Currency_Symbol'
    }, {
      name: 'Sk',
      alias: 'Modifier_Symbol'
    }, {
      name: 'Sm',
      alias: 'Math_Symbol'
    }, {
      name: 'So',
      alias: 'Other_Symbol'
    }, {
      name: 'Zl',
      alias: 'Line_Separator'
    }, {
      name: 'Zp',
      alias: 'Paragraph_Separator'
    }, {
      name: 'Zs',
      alias: 'Space_Separator'
    }
  ];

  ucc_of = function(chr) {
    return (UPROPS.getCategory(chr.codePointAt(0)))[0];
  };

  thin_out = function(list) {
    var i, len, results, x;
    results = [];
    for (i = 0, len = list.length; i < len; i++) {
      x = list[i];
      if (x !== '') {
        results.push(x);
      }
    }
    return results;
  };

  shorten = function(text) {
    if (text.length < 2) {
      return text;
    } else {
      return text.slice(1, text.length - 1);
    }
  };

  chrrpr = function(text) {
    if (/^\s+$/.test(text)) {
      return CND.reverse(shorten(rpr(text)));
    } else {
      return text;
    }
  };

  flag = true;

  toggle = function() {
    return flag = !flag;
  };

  get_color = function(c1, c2) {
    return function(x) {
      if (toggle()) {
        return c1(x);
      } else {
        return c2(x);
      }
    };
  };

  color = get_color(steel, orange);

  rainbow = function(list) {
    var x;
    return ((function() {
      var i, len, results;
      results = [];
      for (i = 0, len = list.length; i < len; i++) {
        x = list[i];
        results.push(color(chrrpr(x)));
      }
      return results;
    })()).join('');
  };

  join = function(list) {
    return list.join('_');
  };

  PS = require('pipestreams');

  $ = PS.$, map = PS.map;

  step = require('coffeenode-suspend').step;

  f = function() {
    this.$lex = function() {
      var pipeline;
      pipeline = [];
      pipeline.push(this.$as_lines());
      pipeline.push(this.$as_characters());
      pipeline.push(this.$add_uccs());
      pipeline.push(this.$rewrite_lws());
      pipeline.push(this.$group_by_ucc());
      pipeline.push(this.$join_groups());
      return PS.pull(...pipeline);
    };
    this.$as_lines = function() {
      return PS.$split();
    };
    this.$as_characters = function() {
      return PS.map(function(line) {
        return Array.from(line);
      });
    };
    this.$add_uccs = function() {
      return PS.map(function(chrs) {
        var chr, i, len, results;
        results = [];
        for (i = 0, len = chrs.length; i < len; i++) {
          chr = chrs[i];
          results.push([chr, ucc_of(chr)]);
        }
        return results;
      });
    };
    this.$rewrite_lws = function() {
      return PS.map(function(chrs_and_uccs) {
        var chr, ucc;
        return (function() {
          var i, len, ref1, results;
          results = [];
          for (i = 0, len = chrs_and_uccs.length; i < len; i++) {
            ref1 = chrs_and_uccs[i], chr = ref1[0], ucc = ref1[1];
            results.push([chr, (chr === '\x20' ? 'lws' : ucc)]);
          }
          return results;
        })();
      });
    };
    this.$join_groups = function() {
      return PS.map(function(event) {
        var chunk, i, len, ref1;
        ref1 = event.chunks;
        for (i = 0, len = ref1.length; i < len; i++) {
          chunk = ref1[i];
          chunk.chrs = chunk.chrs.join('');
        }
        return event;
      });
    };
    this.$group_by_ucc = function() {
      return $(function(chrs_and_uccs, send) {
        var chr, chrs, chunk, chunks, event, i, len, prv_ucc, ref1, ucc;
        prv_ucc = null;
        chrs = null;
        chunk = null;
        chunks = [];
        event = {
          type: 'line',
          chunks: chunks
        };
        for (i = 0, len = chrs_and_uccs.length; i < len; i++) {
          ref1 = chrs_and_uccs[i], chr = ref1[0], ucc = ref1[1];
          if (ucc !== prv_ucc) {
            if (chunk != null) {
              chunks.push(chunk);
            }
            chrs = [];
            chunk = {
              ucc: ucc,
              chrs: chrs
            };
            prv_ucc = ucc;
          }
          chrs.push(chr);
        }
        if (chunk != null) {
          chunks.push(chunk);
        }
        send(event);
        return null;
      });
    };
    return this.lex = function(text, handler) {
      var Z, pipeline;
      pipeline = [];
      Z = [];
      pipeline.push(PS.new_text_source(text));
      pipeline.push(this.$lex());
      pipeline.push($('null', function(event, send) {
        if (event != null) {
          Z.push(event);
          send(event);
        } else {
          handler(null, Z);
        }
        return null;
      }));
      pipeline.push(PS.$drain());
      return PS.pull(...pipeline);
    };
  };

  FM = {};

  f.apply(FM.LEXER = {});


  /*
  
  #-----------------------------------------------------------------------------------------------------------
  TAP.test "basic model", ( T ) ->
    debug '-----------------------------------------------'
    debug "basic model"
    debug '-----------------------------------------------'
     * Randex  = require 'randexp'
     * randex  = new Randex /[-\x20a-z0-9\/()\[\]§$%^°+*´`=?]{0,150}/
    probes_and_matchers = [
      [ 'ab++c23\nd"axyzd\t++dy',   'ab_++_c_23_\n_d_"_a_xyz_d_\t_++_d_y', ]
      [ 'ab++c23\nd"xyzd\t++dy',  'ab_++_c_23_\n_d_"_xyz_d_\t_++_d_y', ]
      [ 'u-cjk-xb/22f33 𢼳 ⿰匡夊','']
      [ 'y = x ** 2 for x in [ 1, 2, 3, ]','']
      ]
    thin_out  = ( list ) -> ( x for x in list when x isnt '' )
    join      = ( list ) -> list.join '_'
    self = this
    step ( resume ) ->
      for [ probe, matcher, ] in probes_and_matchers
        urge rpr probe
        urge yield FM.LEXER.lex probe, resume
         * result  = join thin_out probe.split splitter
         * debug thin_out probe.split splitter
         * whisper rpr result
         * whisper rpr matcher
         * T.ok result is matcher
      T.end()
      return null
    #.........................................................................................................
    return null
   */

  FM['has-transforms'] = true;

  FM.LEXER['has-transforms'] = true;

  this.walk_transforms = function(root, prefix = null) {
    return this._walk_transforms(root, prefix, {});
  };

  this._walk_transforms = function(root, prefix = null, R) {
    var description, descriptor, key, method, name, path, ref1, type;
    if (prefix != null) {
      if (!CND.isa_list(prefix)) {
        prefix = [prefix];
      }
    } else {
      prefix = [];
    }
    ref1 = Object.getOwnPropertyDescriptors(root);
    for (name in ref1) {
      descriptor = ref1[name];
      method = descriptor.value;
      switch (type = CND.type_of(method)) {
        case 'pod':
          if (!method['has-transforms']) {
            continue;
          }
          prefix.push(name);
          return this._walk_transforms(method, prefix, R);
          prefix.pop();
          break;
        case 'function':
          if (!name.startsWith('$')) {
            continue;
          }
          key = name.slice(1).replace(/_/g, '-');
          path = PATH.join(...prefix, key);
          description = method.description;
          if (description == null) {
            description = {};
          }
          R[path] = {
            method: method,
            description: description
          };
      }
    }
    return R;
  };

  debug('89883', this.walk_transforms(FM, 'FM'));

  debug('89883', FM);

  LTSORT = require('ltsort');

  f = function() {
    this.new_graph = function(prefix) {
      var R;
      R = LTSORT.new_graph({
        loners: false

        /* TAINT use library-specific symbol */
      });
      R['%prefix'] = prefix != null ? prefix : '';
      R['%attachments'] = {};
      return R;
    };
    this.attach = function(me, need, key) {
      var base, ref, target;
      need = this._resolve_path(me, need);
      ref = this._resolve_path(me, key);
      target = (base = me['%attachments'])[need] != null ? base[need] : base[need] = [];
      target.push(key);
      return null;
    };
    this._resolve_path = function(me, key) {
      var R, prefix;
      prefix = me['%prefix'];
      R = PATH.resolve('/', me['%prefix'], key);
      if (!PATH.isAbsolute(prefix)) {
        R = PATH.relative('/', R);
      }
      return R;
    };
    this.add = function(me, key, description) {
      var consequent, feed, feeds, i, j, len, len1, need, needs, precedent, ref;
      needs = null;
      feeds = null;
      if (description != null) {
        needs = description.needs, feeds = description.feeds;
      }
      if (needs == null) {
        needs = [];
      }
      if (feeds == null) {
        feeds = [];
      }
      needs = this._pluralize(null, needs);
      feeds = this._pluralize(null, feeds);
      needs = (function() {
        var i, len, results;
        results = [];
        for (i = 0, len = needs.length; i < len; i++) {
          need = needs[i];
          results.push(this._resolve_path(me, need));
        }
        return results;
      }).call(this);
      feeds = (function() {
        var i, len, results;
        results = [];
        for (i = 0, len = feeds.length; i < len; i++) {
          feed = feeds[i];
          results.push(this._resolve_path(me, feed));
        }
        return results;
      }).call(this);
      ref = this._resolve_path(me, key);
      this._add_start_and_stop(me, ref);
      this._add_start_and_stop(me, needs);
      this._add_start_and_stop(me, feeds);
      for (i = 0, len = needs.length; i < len; i++) {
        precedent = needs[i];
        LTSORT.add(me, precedent, ref);
      }
      for (j = 0, len1 = feeds.length; j < len1; j++) {
        consequent = feeds[j];
        LTSORT.add(me, ref, consequent);
      }
      return null;
    };
    this._pluralize = function(_, x) {
      if (CND.isa_list(x)) {
        return x;
      } else {
        return [x];
      }
    };
    this._add_start_and_stop = function(me, path_or_paths) {
      var i, len, path, paths;
      paths = this._pluralize(null, path_or_paths);
      for (i = 0, len = paths.length; i < len; i++) {
        path = paths[i];
        if (path !== '~START') {
          LTSORT.add(me, '~START', path);
        }
        if (path !== '~STOP') {
          LTSORT.add(me, path, '~STOP');
        }
      }
      return null;
    };

    /* TAINT should honor result of `@group` method */
    this.get_linearity = function(me, ...P) {
      return LTSORT.get_linearity(me, ...P);
    };
    this.group = function(me, ...P) {

      /* TAINT should only push attachments to current group when group length > 1 */
      var R, attachment, attachments, group, groups, i, j, k, len, len1, len2, ref, target;
      groups = LTSORT.group(me, ...P);
      R = [];
      for (i = 0, len = groups.length; i < len; i++) {
        group = groups[i];
        target = [];
        R.push(target);
        for (j = 0, len1 = group.length; j < len1; j++) {
          ref = group[j];
          target.push(ref);

          /* TAINT code duplication */
          if ((attachments = me['%attachments'][ref]) == null) {
            continue;
          }
          for (k = 0, len2 = attachments.length; k < len2; k++) {
            attachment = attachments[k];
            target.push(attachment);
          }
        }
      }
      return R;
    };
    return this.linearize = function(me, ...P) {
      var R, attachment, attachments, i, j, len, len1, ref, refs;
      refs = LTSORT.linearize(me, ...P);
      R = [];
      for (i = 0, len = refs.length; i < len; i++) {
        ref = refs[i];
        R.push(ref);

        /* TAINT code duplication */
        if ((attachments = me['%attachments'][ref]) == null) {
          continue;
        }
        for (j = 0, len1 = attachments.length; j < len1; j++) {
          attachment = attachments[j];
          R.push(attachment);
        }
      }
      return R;
    };
  };

  f.apply(XXX = {});

  entries = [
    ['LEXER/as-lines'], [
      'LEXER/as-characters', {
        needs: 'LEXER/as-lines'
      }
    ], [
      'LEXER/add-uccs', {
        needs: 'LEXER/as-characters'
      }
    ], [
      'LEXER/rewrite-lws', {
        needs: 'LEXER/add-uccs',
        feeds: 'LEXER/group-by-ucc'
      }
    ], [
      'LEXER/group-by-ucc', {
        needs: 'LEXER/add-uccs'
      }
    ], [
      'LEXER/join-groups', {
        needs: 'LEXER/group-by-ucc'
      }
    ]
  ];

  show = function(graph) {
    var group, i, j, key, len, len1, ref1, ref2;
    ref1 = XXX.linearize(graph);
    for (i = 0, len = ref1.length; i < len; i++) {
      key = ref1[i];
      help(key);
    }
    ref2 = XXX.group(graph);
    for (j = 0, len1 = ref2.length; j < len1; j++) {
      group = ref2[j];
      info(group);
    }
    return info(XXX.get_linearity(graph));
  };

  graph = XXX.new_graph('FM');

  ref1 = CND.shuffle(entries);
  for (i = 0, len = ref1.length; i < len; i++) {
    ref2 = ref1[i], key = ref2[0], description = ref2[1];
    XXX.add(graph, key, description);
  }

  show(graph);

  XXX.attach(graph, 'LEXER/rewrite-lws', '/PS/show');

  show(graph);

  this.get_linearity = function(graph) {

    /* Linearity of a given dependency graph measures how well the dependency relations in a graph
    determine an ordering of its nodes. For a graph that defines a unique, single chain of antecedents and
    consequents, linearity will be 1; for a graph that defines only nodes and no dependency edges, linearity
    will be zero; for all other kind of graphs, linearity will be the inverse of the average group length.
    The linearity of all graphs with a single element is 1. The linearity of the emtpy graph is also 1, since
    that is the limit that is approached taking ever more nodes out of maximally linear as well as out of
    minimally linear (parallel-only) graphs.
     */
    var count, group, groups, j, len1, minimum, shrink, size;
    if (graph['loners']) {
      throw new Error("linearity not implemented for graphs with loners");
    }
    groups = this.group(graph);
    size = groups.length;
    if (size === 0) {
      return 1;
    }
    count = 0;
    for (j = 0, len1 = groups.length; j < len1; j++) {
      group = groups[j];
      count += group.length;
    }
    minimum = 1 / count;
    shrink = 1 - minimum;
    return ((groups.length / count) - minimum) / shrink;
  };

  graph = LTSORT.new_graph({
    loners: false
  });

  LTSORT.add(graph, 'X');

  LTSORT.add(graph, 'Y');

  debug(LTSORT.get_linearity(graph));

  debug(this.get_linearity.apply(LTSORT, [graph]));

  LTSORT.add(graph, 'Z');

  debug(LTSORT.get_linearity(graph));

  debug(this.get_linearity.apply(LTSORT, [graph]));

  LTSORT.add(graph, 'A', 'B');

  LTSORT.add(graph, 'B', 'C');

  ref3 = LTSORT.group(graph);
  for (j = 0, len1 = ref3.length; j < len1; j++) {
    group = ref3[j];
    info(group);
  }

  debug(LTSORT.get_linearity(graph));

  debug(this.get_linearity.apply(LTSORT, [graph]));

  LTSORT.add(graph, 'A', 'a');

  ref4 = LTSORT.group(graph);
  for (k = 0, len2 = ref4.length; k < len2; k++) {
    group = ref4[k];
    info(group);
  }

  debug(LTSORT.get_linearity(graph));

  debug(this.get_linearity.apply(LTSORT, [graph]));

}).call(this);

//# sourceMappingURL=splitting-with-uprops.js.map
